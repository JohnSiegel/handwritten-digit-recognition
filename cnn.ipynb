{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from helpers import normalize_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels: np.ndarray):\n",
    "    '''\n",
    "    one-hot encode labels\n",
    "    @param labels 1D array of labels\n",
    "    \n",
    "    @return one-hot encoded labels\n",
    "    '''\n",
    "    casted_labels = labels.astype(int)\n",
    "    return np.eye(np.unique(casted_labels).shape[0])[casted_labels]\n",
    "\n",
    "def reshape_flat_square_images(images: np.ndarray):\n",
    "    '''\n",
    "    reshape to be a grayscale square\n",
    "    @param image N x TOTAL_PIXELS\n",
    "\n",
    "    @return N x 1 x HEIGHT x WIDTH\n",
    "    '''\n",
    "    dims = np.sqrt(images.shape[1])\n",
    "    if not dims.is_integer():\n",
    "        raise ValueError('Image is not square')\n",
    "    dims = int(dims)\n",
    "    return images.reshape(images.shape[0], 1, dims, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.loadtxt(\"dataset/train.csv\",\n",
    "                 delimiter=\",\", dtype=str) # load training data\n",
    "training_labels = one_hot_encode(training[1:, 0]) # first column is labels\n",
    "training_data = reshape_flat_square_images(normalize_dataset(training[1:, 1:])) # rest of columns are data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Training Samples: \" + str(training_labels.shape[0]))\n",
    "print(\"# Classes: \" + str(training_labels.shape[1]))\n",
    "print(\"Image Height: \" + str(training_data.shape[2]))\n",
    "print(\"Image Width: \" + str(training_data.shape[3]))\n",
    "plt.imshow(training_data[0, 0]) # show first image in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation Functions\n",
    "\n",
    "def im2col(data: np.ndarray, conv: np.ndarray, stride: int, pad: int):\n",
    "    '''\n",
    "    transforms a batch of images into a matrix\n",
    "    \n",
    "    @param data N x 1 x HEIGHT x WIDTH input images\n",
    "    @param conv NUM_FILTERS x 1 x CONV_HEIGHT x CONV_WIDTH convolutional layer\n",
    "    @param stride number of pixels to move the filter each time\n",
    "    @param pad number of pixels to pad the image with\n",
    "\n",
    "    @return CONV_HEIGHT * CONV_WIDTH x NEW_WIDTH * NEW_HEIGHT * NUM_IMAGES\n",
    "    '''\n",
    "    data_padded = np.pad(data, ((0,0), (0,0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    num_images, num_channels, image_height, image_width = data_padded.shape\n",
    "    conv_height = conv.shape[2]\n",
    "    conv_width = conv.shape[3]\n",
    "    output_height = int((image_height + (2 * pad) - conv_height) / stride) + 1\n",
    "    output_width = int((image_width + (2 * pad) - conv_width) / stride) + 1\n",
    "    \n",
    "    # create a 4D view of the padded data to extract image patches\n",
    "    # view has shape (num_images, num_channels, output_height, output_width, conv_height, conv_width)\n",
    "    data_view = np.lib.stride_tricks.as_strided(data_padded,\n",
    "                                                shape=(num_images, num_channels, output_height, output_width, conv_height, conv_width),\n",
    "                                                strides=(data_padded.strides[0], data_padded.strides[1], \n",
    "                                                         stride * data_padded.strides[2], stride * data_padded.strides[3], \n",
    "                                                         data_padded.strides[2], data_padded.strides[3]))\n",
    "    \n",
    "    # reshape the view to a 2D array\n",
    "    # the shape of the array is (num_images * output_height * output_width, num_channels * conv_height * conv_width)\n",
    "    im2col_vector = data_view.reshape(num_images * output_height * output_width, num_channels * conv_height * conv_width)\n",
    "    \n",
    "    return im2col_vector.T # transpose the matrix to match the expected output shape\n",
    "\n",
    "def convolve(data: np.ndarray, im2col_result: np.ndarray, conv: np.ndarray, stride: int):\n",
    "    '''\n",
    "    convolves the data with the im2col result\n",
    "    @param data N x 1 x HEIGHT x WIDTH input images\n",
    "    @param im2col_result CONV_HEIGHT * CONV_WIDTH x NEW_WIDTH * NEW_HEIGHT * NUM_IMAGES\n",
    "    @param conv NUM_FILTERS x 1 x CONV_HEIGHT x CONV_WIDTH convolutional layer\n",
    "    @param stride number of pixels to move the filter each time\n",
    "    \n",
    "    @return NUM_IMAGES x NUM_FILTERS x NEW_HEIGHT x NEW_WIDTH\n",
    "    '''\n",
    "    num_images, _, height, width = data.shape\n",
    "    num_filters, _, conv_height, conv_width = conv.shape\n",
    "    new_height = int(((height - conv_height) / stride)) + 1\n",
    "    new_width = int(((width - conv_width) / stride)) + 1\n",
    "    \n",
    "    im2col_reshaped = im2col_result.reshape(conv_height * conv_width, new_width * new_height * num_images)\n",
    "    conv_reshaped = conv.reshape(num_filters, -1)\n",
    "    \n",
    "    output = conv_reshaped @ im2col_reshaped\n",
    "    output = output.reshape(num_images, num_filters, new_height, new_width)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def ReLU(x: np.ndarray):\n",
    "    '''\n",
    "    Rectified Linear Unit activation function\n",
    "    \n",
    "    @param x input to the activation function\n",
    "    @return x if x > 0, 0 otherwise\n",
    "    '''\n",
    "    return (x > 0) * x\n",
    "\n",
    "def maxpool_with_indices(data: np.ndarray, pool_size: int, stride: int):\n",
    "    '''\n",
    "    computes the maxpooling of the input data\n",
    "    @param data N x CHANNELS x HEIGHT x WIDTH input images\n",
    "    @param pool_size size of the pooling filter\n",
    "    @param stride number of pixels to move the filter each time\n",
    "    \n",
    "    @return A tuple (max_output, indices) where:\n",
    "            max_output is N x CHANNELS x NEW_HEIGHT x NEW_WIDTH\n",
    "            indices is N x CHANNELS x NEW_HEIGHT x NEW_WIDTH x pool_size^2\n",
    "    '''\n",
    "    # Get input shape\n",
    "    N, C, H, W = data.shape\n",
    "\n",
    "    # Compute output shape\n",
    "    OH = (H - pool_size) // stride + 1\n",
    "    OW = (W - pool_size) // stride + 1\n",
    "\n",
    "    # Pad input data to handle edge cases\n",
    "    pad_height = ((OH - 1) * stride + pool_size - H) // 2\n",
    "    pad_width = ((OW - 1) * stride + pool_size - W) // 2\n",
    "    data = np.pad(data, ((0, 0), (0, 0), (pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "\n",
    "    # Create view of data with desired strides\n",
    "    data_strided = np.lib.stride_tricks.as_strided(data,\n",
    "                                                shape=(N, C, OH, OW, pool_size, pool_size),\n",
    "                                                strides=(data.strides[0],\n",
    "                                                         data.strides[1],\n",
    "                                                         stride * data.strides[2],\n",
    "                                                         stride * data.strides[3],\n",
    "                                                         data.strides[2],\n",
    "                                                         data.strides[3]))\n",
    "\n",
    "    # Compute max pooling and indices\n",
    "    max_output = np.max(data_strided, axis=(4, 5))\n",
    "    indices = np.argmax(data_strided, axis=4), np.argmax(data_strided, axis=5)\n",
    "    indices = np.ravel_multi_index(indices, (pool_size, pool_size))\n",
    "    idx_h, idx_w = np.unravel_index(indices, (pool_size, pool_size))\n",
    "    idx_h = idx_h.reshape(N, C, OH, OW, -1)\n",
    "    idx_w = idx_w.reshape(N, C, OH, OW, -1)\n",
    "    indices = np.concatenate((idx_h, idx_w), axis=-1)\n",
    "    \n",
    "    return max_output, indices\n",
    "\n",
    "def softmax(data: np.ndarray):\n",
    "    '''\n",
    "    Computes the softmax function for each row of the input x.\n",
    "    @param data N x D matrix where N is the number of samples and D is the number of classes\n",
    "    \n",
    "    @return N x D matrix where each row is a valid probability distribution\n",
    "    '''\n",
    "    data_exp = np.exp(data-np.max(data))\n",
    "    \n",
    "    return data_exp / np.sum(data_exp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation Functions\n",
    "\n",
    "def dReLU(x: np.ndarray):\n",
    "    '''\n",
    "    Derivative of the Rectified Linear Unit activation function\n",
    "    @param x input to the activation function\n",
    "    \n",
    "    @return 1.0 if x > 0, 0 otherwise\n",
    "    '''\n",
    "    return (x > 0) * 1.0\n",
    "\n",
    "def unpool_with_indices(delta_maxpool: np.ndarray, maxpool_indices: np.ndarray, pool_size: int):\n",
    "    '''\n",
    "    Unpools the given delta_maxpool using the maxpool_indices.\n",
    "    @param delta_maxpool N x CHANNELS x HEIGHT x WIDTH array of max-pooled gradients\n",
    "    @param maxpool_indices N x CHANNELS x NEW_HEIGHT x NEW_WIDTH x pool_size^2 array of indices\n",
    "    @param pool_size size of the pooling filter used in the max-pooling operation\n",
    "    \n",
    "    @return delta_unpooled N x CHANNELS x (HEIGHT * pool_size) x (WIDTH * pool_size) array of unpooled gradients\n",
    "    '''\n",
    "    N, C, _, _, _ = maxpool_indices.shape\n",
    "    _, _, H, W = delta_maxpool.shape\n",
    "\n",
    "    delta_unpooled = np.zeros((N, C, H * pool_size, W * pool_size), dtype=delta_maxpool.dtype)\n",
    "\n",
    "    for i in range(pool_size):\n",
    "        for j in range(pool_size):\n",
    "            mask = (maxpool_indices[..., 0] == i) & (maxpool_indices[..., 1] == j)\n",
    "            delta_unpooled[..., i::pool_size, j::pool_size] += delta_maxpool * mask\n",
    "\n",
    "    return delta_unpooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 2\n",
    "conv_filter_size = 5\n",
    "conv_stride = 1\n",
    "conv_layer = np.random.randn(num_filters, 1, conv_filter_size, conv_filter_size) * np.sqrt(1. / conv_filter_size)\n",
    "display(conv_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_im2col = im2col(training_data[0:1], conv_layer, conv_stride, 0) # only use one image\n",
    "display(single_im2col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_conv = convolve(training_data[0:1], single_im2col, conv_layer, conv_stride) # convolve the first training image with the first filter\n",
    "single_conv = ReLU(single_conv) # apply ReLU activation function\n",
    "plt.imshow(single_conv[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_size = 2\n",
    "maxpool_stride = 2\n",
    "single_maxpool, single_maxpool_indices = maxpool_with_indices(single_conv[0:1], maxpool_size, maxpool_stride) # maxpool the first image\n",
    "plt.imshow(single_maxpool[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and biases\n",
    "W1 = np.random.rand(60, 288) / np.sqrt(288)\n",
    "B0 = np.zeros((60, 1)) / np.sqrt(288)\n",
    "W2 = np.random.rand(10, 60) / np.sqrt(60)\n",
    "B1 = np.zeros((10, 1)) / np.sqrt(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_single_maxpool = single_maxpool.reshape(-1, single_maxpool.shape[0]) # flatten the output of the maxpool layer\n",
    "single_fully_connected = ReLU(W1 @ flat_single_maxpool + B0) # apply the first fully connected layer\n",
    "display(single_fully_connected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_final = np.argmax(softmax(W2 @ single_fully_connected + B1), axis=0) # apply the second fully connected layer\n",
    "print(\"Final prediction: \" + str(single_final[0]))\n",
    "print(\"Correct label: \" + str(np.argmax(training_labels[0], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "batches = int(training_data.shape[0]/batch_size)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Adam Optimizer parameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[219], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m delta_unpool \u001b[39m=\u001b[39m unpool_with_indices(delta_maxpool, maxpool_indices, maxpool_size) \u001b[39m*\u001b[39m dReLU(conv_res)\n\u001b[0;32m     22\u001b[0m delta_conv \u001b[39m=\u001b[39m (error_layer_reshape(delta_unpool) \u001b[39m@\u001b[39m data_im2col\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mreshape(conv_layer\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 23\u001b[0m display(delta_conv\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m     24\u001b[0m dW1 \u001b[39m=\u001b[39m delta1 \u001b[39m@\u001b[39m flat_maxpool_out\u001b[39m.\u001b[39mT\n\u001b[0;32m     25\u001b[0m dW2 \u001b[39m=\u001b[39m delta2 \u001b[39m@\u001b[39m fully_connected_out\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[39mif\u001b[39;00m metadata:\n\u001b[0;32m    303\u001b[0m             \u001b[39m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[0;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[1;32m--> 305\u001b[0m         publish_display_data(data\u001b[39m=\u001b[39;49mformat_dict, metadata\u001b[39m=\u001b[39;49mmd_dict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    306\u001b[0m \u001b[39mif\u001b[39;00m display_id:\n\u001b[0;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[1;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m transient:\n\u001b[0;32m     91\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mtransient\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m transient\n\u001b[1;32m---> 93\u001b[0m display_pub\u001b[39m.\u001b[39;49mpublish(\n\u001b[0;32m     94\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m     95\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m     96\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m     97\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py:102\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[1;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpublish\u001b[39m(\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     82\u001b[0m     data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     update\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[0;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flush_streams()\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m metadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m         metadata \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py:65\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_flush_streams\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n\u001b[0;32m     66\u001b[0m     sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:495\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m evt \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mEvent()\n\u001b[1;32m--> 495\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(evt\u001b[39m.\u001b[39;49mset)\n\u001b[0;32m    496\u001b[0m \u001b[39m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt\u001b[39m.\u001b[39mwait(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush_timeout):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:211\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    210\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\Users\\jpsie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\zmq\\sugar\\socket.py:620\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    613\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    614\u001b[0m             data,\n\u001b[0;32m    615\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    616\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    617\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    618\u001b[0m         )\n\u001b[0;32m    619\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:746\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:793\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jpsie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    for batch_index in range(batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = min(start_index + batch_size, training_data.shape[0] - 1)\n",
    "        data_batch = training_data[start_index:end_index]\n",
    "        label_batch = training_labels[start_index:end_index].T\n",
    "        data_im2col = im2col(data_batch, conv_layer, conv_stride, 0)\n",
    "        conv_res = convolve(data_batch, data_im2col, conv_layer, conv_stride)\n",
    "        conv_out = ReLU(conv_res) # convolve the first training image with the first filter\n",
    "        maxpool_out, maxpool_indices = maxpool_with_indices(conv_out, maxpool_size, maxpool_stride) # maxpool the first image\n",
    "        flat_maxpool_out = maxpool_out.reshape(-1, maxpool_out.shape[0]) # flatten the output of the maxpool layer\n",
    "        fully_connected = W1 @ flat_maxpool_out + B0 # apply the first fully connected layer\n",
    "        fully_connected_out = ReLU(fully_connected) # apply ReLU activation functions\n",
    "        final_connected = softmax(W2 @ fully_connected_out + B1) # apply the second fully connected layer\n",
    "        \n",
    "        # back propagation\n",
    "        delta2 = final_connected - label_batch\n",
    "        delta1 = (W2.T @ delta2) * dReLU(fully_connected)\n",
    "        delta0 = W1.T @ delta1\n",
    "        delta_maxpool = delta0.reshape(maxpool_out.shape)\n",
    "        delta_unpool = unpool_with_indices(delta_maxpool, maxpool_indices, maxpool_size) * dReLU(conv_res)\n",
    "        delta_conv = (delta_unpool.transpose(1, 0, 2, 3).reshape(delta_unpool.shape[1], -1) @ data_im2col.T).reshape(conv_layer.shape)\n",
    "        display(delta_conv.shape)\n",
    "        dW1 = delta1 @ flat_maxpool_out.T\n",
    "        dW2 = delta2 @ fully_connected_out.T\n",
    "        dB0 = np.sum(delta1, axis=1, keepdims=True)\n",
    "        dB1 = np.sum(delta2, axis=1, keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
