{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecdf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM implementation for hand digits recognition\n",
    "# This SVM use multiclass SVM model\n",
    "# The whole process is to use binary SVM combined with One-to-rest strategy\n",
    "# The hand digits recognition has label 0-9\n",
    "# However, binary SVM can only classify data into two catogories\n",
    "# Multiclass SVM is to select one specific digits label and compare to other digits\n",
    "# The select digits is relabeled as +1, others as -1\n",
    "# For each digit label, we use binary SVM to classify this one to rest\n",
    "# Then obtain the score of the selected digits\n",
    "# After obtaining all scores of the pixel data which are fitted in all 10 labels\n",
    "# The highest score label is the label we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f74e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from quadprog_wrapper import solve_quadprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398ec7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from training set and test set\n",
    "trainData = pd.read_csv('train.csv')\n",
    "testData = pd.read_csv('test.csv')\n",
    "\n",
    "# Set number of samples needed from each digits subgroup\n",
    "# Larger size means higher accuracy\n",
    "# But it also takes more time training\n",
    "sample_count = 200 #  <<== YOU MAY CHANGE THIS SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60839c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_svm_train(data, labels):\n",
    "    '''\n",
    "    Implementation of binary SVM\n",
    "    This function is to use data and its label to perform binary SVM\n",
    "    The data will be catogorized in binary class\n",
    "    @param Data Dataset for binary SVM training\n",
    "    @param Labels labels identified for each point, binary format\n",
    "    \n",
    "    @return Factors contribute to prediction, including weights, bias, support vectors and correspond label\n",
    "    '''\n",
    "    # Use polynomial kernel to obtain the feature of data matrix\n",
    "    g_mat = (np.dot(data.T, data) + 1) ** 2\n",
    "    \n",
    "    # Obtain the row size of gram matrix, use for later computation\n",
    "    n = g_mat.shape[0]\n",
    "    \n",
    "    # Hessian Matrix describes the local curvature of a function of many variables\n",
    "    # It provides hessian matrix for solving quadprog problem\n",
    "    hes = np.outer(labels, labels) * g_mat\n",
    "    \n",
    "    # Weights, linear coefficents for the gram matrix\n",
    "    # Initial weights are all 0\n",
    "    w = np.ones(n)\n",
    "    \n",
    "    # Linear coefficients for the equality constraints\n",
    "    coef = np.zeros((1, n))\n",
    "    coef[0, :] = labels\n",
    "\n",
    "    # Solve quadratic programming problem, store result to alpha matrix as a\n",
    "    # (Hessian, weights, eq_coeffs, eq_constants, ineq_coeffs, ineq_constants, lower_bounds, upper_bounds)\n",
    "    a = solve_quadprog(hes, w, coef, np.zeros(1), None, None, np.zeros(n), 1.0)\n",
    "\n",
    "    # Select alphas which have nonnegligible support\n",
    "    vec_idx = a > 1e-6\n",
    "    v = data[:, vec_idx]\n",
    "    \n",
    "    # Replace weight with nonnegligible support alphas. Same as labels\n",
    "    w_fix = a[vec_idx]\n",
    "    l = labels[vec_idx]\n",
    "\n",
    "    # Find all alphas which are useful in the decision margin\n",
    "    # Logical AND generates boolean array meets condition in parameter\n",
    "    # That alphas indicates the useful one which has value TRUE\n",
    "    marg_a = np.logical_and(a > 1e-6, a < 1.0 - 1e-6)\n",
    "\n",
    "    # Compute bias\n",
    "    if np.any(marg_a):\n",
    "        # Bias is average value of transpose(label) - transpose(alpha * label) dot (gram matrix TRUE alpha part)\n",
    "        b = np.mean(labels[marg_a].T - (a * labels).T.dot(g_mat[:, marg_a]))\n",
    "    else:\n",
    "        # No support vectors\n",
    "        b = 0\n",
    "        \n",
    "    return v, w_fix, l, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0209c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(data, w, b, v, l):\n",
    "    '''\n",
    "    Generate score of the prediction\n",
    "    Use polynomial kernel to generate gram matrix and get scores\n",
    "    @param data Dataset for binary SVM prediction\n",
    "    @param w Weights\n",
    "    @param b Bias\n",
    "    @param v Support Vector\n",
    "    @param l Labels correspond to Support Vector\n",
    "    @return Scores of prediction\n",
    "    '''\n",
    "    # Gram matrix using polynomial kernel\n",
    "    gram = (np.dot(data.T, v) + 1) ** 2\n",
    "    # y = w x + b\n",
    "    scores = gram.dot(w * l) + b\n",
    "    return scores.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627317a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(num, sample_set):\n",
    "    '''\n",
    "    Convert label from 0-9 to +1 or -1\n",
    "    @param num Choose label of data, value is 0-9, this one will be evaluated as +1\n",
    "    @param sample_set Dataset to relabel\n",
    "    @return Dataset in binary label form\n",
    "    '''\n",
    "    # Deep copy of original data\n",
    "    binary = sample_set.copy(deep=True)\n",
    "    \n",
    "    # Remark labels\n",
    "    binary.loc[binary['label'] != num, 'label'] = -1\n",
    "    binary.loc[binary['label'] == num, 'label'] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73662bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data):\n",
    "    '''\n",
    "    Use binary SVM to train recognizing and catogorizing the pixel to labels\n",
    "    This function will get copy of original data and parse this data into label part and pixel part\n",
    "    Then normalize the value in pixel part from 0-255 to 0-1\n",
    "    Finally use the processed pixel data to obtain training score\n",
    "    @param data Raw data which has label and pixels in same dataset\n",
    "    @return Factors contribute to prediction, including weights, bias, support vectors and correspond label\n",
    "    '''\n",
    "    raw_set = data.copy(deep=True)\n",
    "    # Obtain the label of raw data and transfer to numbers only\n",
    "    raw_set_label = raw_set['label']\n",
    "    raw_set_label = raw_set_label.values\n",
    "    \n",
    "    # Obtain the pixel data part of raw data and transfer to numbers only, then normalize\n",
    "    raw_set_data = raw_set.drop(columns=['label'], inplace=True)\n",
    "    raw_set_data = raw_set.values/255.0\n",
    "    \n",
    "    # Use the processed data to apply on binary SVM to get the score\n",
    "    [vec, w, vec_lb, b] = bin_svm_train(raw_set_data.T, raw_set_label)\n",
    "    return w, b, vec, vec_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4114aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_to_rest_train(train_data, sample_num):\n",
    "    '''\n",
    "    Use one to rest SVM to train\n",
    "    This function will parse the training dataset and use one to rest SVM strategy\n",
    "    Then return the factors for prediction use\n",
    "    @param train_data: Training dataset\n",
    "    @param sample_num: Number of sample from each digit subgroup\n",
    "    @return Factors contribute to prediction, including weights, bias, support vectors and correspond label\n",
    "    '''\n",
    "    # Catagorize the dataset into subset 0-9\n",
    "    group = train_data.groupby('label')\n",
    "\n",
    "    # Store these dataset to each group\n",
    "    zero = pd.DataFrame(group.get_group(0))\n",
    "    one = pd.DataFrame(group.get_group(1))\n",
    "    two = pd.DataFrame(group.get_group(2))\n",
    "    three = pd.DataFrame(group.get_group(3))\n",
    "    four = pd.DataFrame(group.get_group(4))\n",
    "    five = pd.DataFrame(group.get_group(5))\n",
    "    six = pd.DataFrame(group.get_group(6))\n",
    "    seven = pd.DataFrame(group.get_group(7))\n",
    "    eight = pd.DataFrame(group.get_group(8))\n",
    "    nine = pd.DataFrame(group.get_group(9))\n",
    "\n",
    "    # Obtain the pure pixel datasets\n",
    "    zero_data = zero.drop(columns=['label'])\n",
    "    one_data = one.drop(columns=['label'])\n",
    "    two_data = two.drop(columns=['label'])\n",
    "    three_data = three.drop(columns=['label'])\n",
    "    four_data = four.drop(columns=['label'])\n",
    "    five_data = five.drop(columns=['label'])\n",
    "    six_data = six.drop(columns=['label'])\n",
    "    seven_data = seven.drop(columns=['label'])\n",
    "    eight_data = eight.drop(columns=['label'])\n",
    "    nine_data = nine.drop(columns=['label'])\n",
    "\n",
    "    # Set random sample size from each label group for training\n",
    "    # WARNING: The ONE TO REST SVM requires a lot of time\n",
    "    # Larger sample number may cause long time training\n",
    "    count = sample_num\n",
    "\n",
    "    # Random select\n",
    "    rdm_zero = zero.sample(count)\n",
    "    rdm_one = one.sample(count)\n",
    "    rdm_two = two.sample(count)\n",
    "    rdm_three = three.sample(count)\n",
    "    rdm_four = four.sample(count)\n",
    "    rdm_five = five.sample(count)\n",
    "    rdm_six = six.sample(count)\n",
    "    rdm_seven = seven.sample(count)\n",
    "    rdm_eight = eight.sample(count)\n",
    "    rdm_nine = nine.sample(count)\n",
    "\n",
    "    # Concrete selected sample training data into whole dataset\n",
    "    sample_set = rdm_zero\n",
    "    sample_set = sample_set.append(rdm_one)\n",
    "    sample_set = sample_set.append(rdm_two)\n",
    "    sample_set = sample_set.append(rdm_three)\n",
    "    sample_set = sample_set.append(rdm_four)\n",
    "    sample_set = sample_set.append(rdm_five)\n",
    "    sample_set = sample_set.append(rdm_six)\n",
    "    sample_set = sample_set.append(rdm_seven)\n",
    "    sample_set = sample_set.append(rdm_eight)\n",
    "    sample_set = sample_set.append(rdm_nine)\n",
    "\n",
    "    # Critical process of ONE TO REST SVM\n",
    "\n",
    "    # Relabel the dataset to primary set with +1 and rest sets with -1\n",
    "    # E.g. If we want to know the score of label 0 we need to label the \"0\" ones to +1 and other sets to be -1\n",
    "    class_zero = relabel(0, sample_set)\n",
    "    class_one = relabel(1, sample_set)\n",
    "    class_two = relabel(2, sample_set)\n",
    "    class_three = relabel(3, sample_set)\n",
    "    class_four = relabel(4, sample_set)\n",
    "    class_five = relabel(5, sample_set)\n",
    "    class_six = relabel(6, sample_set)\n",
    "    class_seven = relabel(7, sample_set)\n",
    "    class_eight = relabel(8, sample_set)\n",
    "    class_nine = relabel(9, sample_set)\n",
    "\n",
    "    # Use binary SVM training to obtain four parts data for evaluating trends of each dataset\n",
    "    w = [None] * 10 # weights, which is w in w x + b\n",
    "    b = [None] * 10 # bias, which is b in w x + b\n",
    "    v = [None] * 10 # support vectors, which is used for prediction\n",
    "    l = [None] * 10 # labels correspond to support vectors, which is used for prediction\n",
    "    [w[0], b[0], v[0], l[0]] = training(class_zero)\n",
    "    [w[1], b[1], v[1], l[1]] = training(class_one)\n",
    "    [w[2], b[2], v[2], l[2]] = training(class_two)\n",
    "    [w[3], b[3], v[3], l[3]] = training(class_three)\n",
    "    [w[4], b[4], v[4], l[4]] = training(class_four)\n",
    "    [w[5], b[5], v[5], l[5]] = training(class_five)\n",
    "    [w[6], b[6], v[6], l[6]] = training(class_six)\n",
    "    [w[7], b[7], v[7], l[7]] = training(class_seven)\n",
    "    [w[8], b[8], v[8], l[8]] = training(class_eight)\n",
    "    [w[9], b[9], v[9], l[9]] = training(class_nine)\n",
    "    return w, b, v, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_to_rest_predict(test_data, w, b, v, l):\n",
    "    '''\n",
    "    Predict the test data and obtain number of correct prediction\n",
    "    @param test_data Test dataset\n",
    "    @param w Weights\n",
    "    @param b Bias\n",
    "    @param v Support Vector\n",
    "    @param l Labels correspond to Support Vector\n",
    "    @return Number of correct prediction\n",
    "    '''\n",
    "    # Obtain the raw data from test dataset\n",
    "    testCut = test_data.copy(deep=True)\n",
    "\n",
    "    # Obtain label part from raw data\n",
    "    label = testCut['label']\n",
    "\n",
    "    # Obtain pixel part from raw data\n",
    "    testCut.drop(columns = ['label'], inplace=True)\n",
    "\n",
    "    # Normalize the pixel data\n",
    "    testCut = testCut.values/255.0\n",
    "\n",
    "    # Use the training knowledge to predict test data\n",
    "    correct = 0 # Count for correct prediction\n",
    "    # Prediction for each row of data in the test dataset\n",
    "    for j in range(testCut.shape[0]):\n",
    "        piece = testCut[j] # Single row of data\n",
    "        result = [None] * 10 # Score array to store the score of each label from 0-9\n",
    "        # Store prediction evaluating scores to score array correspond to label 0-9\n",
    "        for i in range(10):\n",
    "            result[i] = svm_predict(piece, w[i], b[i], v[i], l[i])\n",
    "        # The final prediction label should be the label which has highest score\n",
    "        value = result.index(max(result))\n",
    "        # Increment correct prediction count\n",
    "        if (value == label.iloc[j]):\n",
    "            correct = correct + 1\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25a5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(sub, w, b, v, l):\n",
    "    '''\n",
    "    Get accuracy for data prediction\n",
    "    @param sub Dataset, can be all data or subgroup of data\n",
    "    @param w Weights\n",
    "    @param b Bias\n",
    "    @param v Support Vector\n",
    "    @param l Labels correspond to Support Vector\n",
    "    @return Accuracy of prediction\n",
    "    '''\n",
    "    correct_count = one_to_rest_predict(sub, w, b, v, l)\n",
    "    accuracy = correct_count / sub.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958bdc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of digit 0 is: 97.25%\n",
      "Accuracy of digit 1 is: 97.53%\n",
      "Accuracy of digit 2 is: 93.02%\n",
      "Accuracy of digit 3 is: 87.84%\n",
      "Accuracy of digit 4 is: 96.14%\n",
      "Accuracy of digit 5 is: 94.20%\n",
      "Accuracy of digit 6 is: 95.40%\n",
      "Accuracy of digit 7 is: 93.64%\n",
      "Accuracy of digit 8 is: 90.60%\n",
      "Accuracy of digit 9 is: 87.66%\n",
      "Overall accuracy is: 93.45%\n"
     ]
    }
   ],
   "source": [
    "# Use multiclass SVM to train the data\n",
    "[w, b, v, l] = one_to_rest_train(trainData, sample_count)\n",
    "\n",
    "# Parse test dataset to digits 0-9 group\n",
    "group = testData.groupby('label')\n",
    "\n",
    "# Obtain accuracy of prediction for each digits\n",
    "for i in range(10):\n",
    "    sub = pd.DataFrame(group.get_group(i))\n",
    "    sub_accuracy= get_acc(sub, w, b, v, l)\n",
    "    print(\"Accuracy of digit %d is: %.2f%%\" % (i, sub_accuracy * 100))\n",
    "\n",
    "# Obtain overall accuracy of prediction for all\n",
    "correct_count = one_to_rest_predict(testData, w, b, v, l)\n",
    "accuracy = correct_count / testData.shape[0]\n",
    "print(\"Overall accuracy is: %.2f%%\" % (accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
